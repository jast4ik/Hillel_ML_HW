{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 11:17:53.898272: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-04 11:17:53.898326: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed = 42\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras_tuner import HyperParameters, Hyperband\n",
    "\n",
    "from os.path import isfile\n",
    "\n",
    "import lzma\n",
    "\n",
    "import pickle\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax import jax_utils\n",
    "import optax\n",
    "\n",
    "import time\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Импорт данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализация исходных данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "# axs = ax.flatten()\n",
    "\n",
    "# letters_idx = np.random.randint(0, X_test.shape[0], len(axs))\n",
    "\n",
    "# for idx in range(len(axs)):\n",
    "#     axs[idx].imshow(X_test[letters_idx[idx]], cmap='gray_r')\n",
    "#     axs[idx].set_title(y_test[letters_idx[idx]])\n",
    "#     axs[idx].xaxis.set_ticks([])\n",
    "#     axs[idx].yaxis.set_ticks([])\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, depth = X_train.shape[1], X_train.shape[2], 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], width, height, depth)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], width, height, depth)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аугментация**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мне показалось скучным работать с исходными данными - слишком они хороши. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_SHIFT = [-1, 1]\n",
    "H_SHIFT = [-1, 1]\n",
    "ROT_ANGLE = 20\n",
    "ZOOM_RANGE = [0.7, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "P_WIDTH = 28\n",
    "P_HEIGHT = 28\n",
    "P_DEPTH = 1\n",
    "N_CLASSES = 10\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я много раз читал о создании валидационного датасета, который является частью тренировочного. Лучше один раз сделать, чем сто раз прочитать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, генератор можно настроить на разделение датасета. Чтобы не делать несколько отдельных. Но мне показалось так интереснее. Серьезного обоснования такому решению нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    width_shift_range=W_SHIFT, \n",
    "    height_shift_range=H_SHIFT,\n",
    "    rotation_range=ROT_ANGLE,\n",
    "    zoom_range=ZOOM_RANGE,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale= 1.0/255.0\n",
    ")\n",
    "\n",
    "train_generator.fit(X_train)\n",
    "train_iterator = train_generator.flow(X_train, y_train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = ImageDataGenerator(\n",
    "    width_shift_range=W_SHIFT, \n",
    "    height_shift_range=H_SHIFT,\n",
    "    rotation_range=ROT_ANGLE,\n",
    "    zoom_range=ZOOM_RANGE,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale= 1.0/255.0\n",
    ")\n",
    "\n",
    "val_generator.fit(X_val)\n",
    "val_iterator = val_generator.flow(X_val, y_val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "test_generator.fit(X_test)\n",
    "test_iterator = test_generator.flow(X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализация аугментированных данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "# axs = ax.flatten()\n",
    "\n",
    "# for idx in range(len(axs)):\n",
    "#     letter_idx = round(letters_idx[idx]/BATCH_SIZE)\n",
    "#     random_bath_idx = random.choice(range(BATCH_SIZE))\n",
    "    \n",
    "#     axs[idx].imshow(train_iterator[letter_idx][0][random_bath_idx], cmap='gray_r')\n",
    "    \n",
    "#     img_label = np.nonzero(train_iterator[letter_idx][1][random_bath_idx])\n",
    "    \n",
    "#     axs[idx].set_title(int(img_label[0]))\n",
    "#     axs[idx].xaxis.set_ticks([])\n",
    "#     axs[idx].yaxis.set_ticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модель**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня нет серьезного обоснования, почему я взял именно такую структуру. Это некоторая комбинация изученных примеров и моего понимания свёрточных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_keras_model(hp):\n",
    "    \n",
    "#     hp_filters_l1 = hp.Int(name='filters L1', min_value=16, max_value=128, step=16, default=32)\n",
    "#     hp_filters_l2 = hp.Int(name='filters L2', min_value=16, max_value=128, step=16, default=64)\n",
    "#     hp_weights = hp.Choice(name='kernel_initializer', values=['he_uniform', 'he_normal', 'normal', 'uniform', 'glorot_uniform', 'glorot_normal'], default='he_uniform')\n",
    "#     hp_funcs = hp.Choice(name='activation', values=['relu', 'sigmoid', 'tanh'], default='relu')\n",
    "#     hp_units = hp.Int(name='units', min_value=64, max_value=2048, step=64, default=128) \n",
    "#     hp_rates = hp.Float(name='rate', min_value=0.0, max_value=0.5, step=0.05, default=0.25)\n",
    "#     hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4], default=1e-3)\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Input((width, height, depth)))\n",
    "\n",
    "#     model.add(Conv2D(filters=hp_filters_l1, kernel_size=(3, 3), activation=hp_funcs, kernel_initializer=hp_weights, padding='same'))\n",
    "#     model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "#     #model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Conv2D(filters=hp_filters_l2, kernel_size=(3, 3), activation=hp_funcs, kernel_initializer=hp_weights, padding='same'))\n",
    "#     model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "#     #model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(units=hp_units, activation=hp_funcs, kernel_initializer=hp_weights))\n",
    "#     model.add(Dropout(rate=hp_rates))\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_from_iterator(steps_count = 0, jax = True, iterator = None):\n",
    "    \"\"\"Generates dataset from ImageDataGenerator\"\"\"\n",
    "\n",
    "    iterator.reset()\n",
    "\n",
    "    result = [[], []]\n",
    "\n",
    "    if jax:\n",
    "        result = {\n",
    "            'image': [], \n",
    "            'label': []\n",
    "        }\n",
    "\n",
    "    for _ in range(steps_count):\n",
    "        batch_ds = tf.data.Dataset.from_generator(\n",
    "            lambda: iterator,\n",
    "            output_types=(tf.float32, tf.float32),\n",
    "            output_shapes=(\n",
    "                [BATCH_SIZE, P_WIDTH, P_HEIGHT, P_DEPTH],\n",
    "                [BATCH_SIZE, N_CLASSES]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        temp_ds_iterator = iter(batch_ds)\n",
    "        batch = next(temp_ds_iterator)\n",
    "\n",
    "        if jax:\n",
    "            result['image'].append(tfds.as_numpy(batch[0]))\n",
    "            result['label'].append(np.argmax(tfds.as_numpy(batch[1]), axis=1))\n",
    "        else:\n",
    "            result[0].append(np.float32(tfds.as_numpy(batch[0])))\n",
    "            result[1].append(np.float32(tfds.as_numpy(batch[1])))\n",
    "    \n",
    "    if jax:\n",
    "        result['image'] = jnp.float32(np.array(result['image']).reshape(steps_count * BATCH_SIZE, P_WIDTH, P_HEIGHT, P_DEPTH))\n",
    "        result['label'] = jnp.float32(np.array(result['label']).flatten())\n",
    "        return result\n",
    "    else:\n",
    "        return np.array(result[0]).reshape(steps_count * BATCH_SIZE, P_WIDTH, P_HEIGHT, P_DEPTH), np.array(result[1]).reshape(steps_count * BATCH_SIZE, N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_iterator.n // train_iterator.batch_size\n",
    "STEP_SIZE_VAL = val_iterator.n // val_iterator.batch_size\n",
    "STEP_SIZE_TEST = test_iterator.n // test_iterator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ds, y_train_ds = make_dataset_from_iterator(STEP_SIZE_TRAIN, False, train_iterator)\n",
    "# X_val_ds, y_val_ds = make_dataset_from_iterator(STEP_SIZE_VAL, False, val_iterator)\n",
    "# X_test_ds, y_test_ds = make_dataset_from_iterator(STEP_SIZE_TEST, False, test_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator.reset()\n",
    "# val_iterator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала натренирую сетку с дефолтными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model = None\n",
    "# keras_history = None\n",
    "\n",
    "# if isfile(\"./models/keras_model.hdf5\"):\n",
    "#     keras_model = load_model(\"./models/keras_model.hdf5\")\n",
    "    \n",
    "#     with lzma.open(\"./models/keras_history.xz\", \"rb\") as m_file:\n",
    "#         keras_history = pickle.load(m_file)\n",
    "# else:\n",
    "#     keras_model = build_keras_model(HyperParameters())\n",
    "#     keras_history = keras_model.fit(\n",
    "#         x=X_train_ds, y=y_train_ds,#train_iterator, \n",
    "#         epochs=NUM_EPOCHS, \n",
    "#         steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#         validation_data=(X_val_ds, y_val_ds),#val_iterator,\n",
    "#         validation_steps=STEP_SIZE_VAL, \n",
    "#         callbacks=[keras_early_stop]\n",
    "#         )\n",
    "  \n",
    "#     keras_model.save(\"./models/keras_model.hdf5\")\n",
    "\n",
    "#     with lzma.open(\"./models/keras_history.xz\", \"wb\") as m_file:\n",
    "#         pickle.dump(keras_history.history, m_file)\n",
    "\n",
    "#     keras_history = keras_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь попробую подобрать гиперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_tuner = Hyperband(\n",
    "#     hypermodel=build_keras_model,\n",
    "#     objective='val_accuracy',\n",
    "#     factor=3,\n",
    "#     max_epochs=10,\n",
    "#     directory='./tf_data', \n",
    "#     project_name='HW14'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras_tuner_early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator.reset()\n",
    "# val_iterator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_tuner.search(\n",
    "#     train_iterator,\n",
    "#     validation_data=val_iterator,\n",
    "#     callbacks=[keras_tuner_early_stop]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tuned_parameters = keras_tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator.reset()\n",
    "# val_iterator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tuned_model = None\n",
    "# best_tuned_history = None\n",
    "\n",
    "# if isfile(\"./models/keras_tuned_model.hdf5\"):\n",
    "#     best_tuned_model = load_model(\"./models/keras_tuned_model.hdf5\")\n",
    "    \n",
    "#     with lzma.open(\"./models/keras_tuned_history.xz\", \"rb\") as m_file:\n",
    "#         best_tuned_history = pickle.load(m_file)\n",
    "# else:\n",
    "#     best_tuned_model = build_keras_model(best_tuned_parameters)\n",
    "#     best_tuned_history = best_tuned_model.fit(\n",
    "#         train_iterator, \n",
    "#         epochs=10, \n",
    "#         steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#         validation_data=val_iterator,\n",
    "#         validation_steps=STEP_SIZE_VAL, \n",
    "#         callbacks=[keras_early_stop]\n",
    "#         )\n",
    "  \n",
    "#     best_tuned_model.save(\"./models/keras_tuned_model.hdf5\")\n",
    "\n",
    "#     with lzma.open(\"./models/keras_tuned_history.xz\", \"wb\") as m_file:\n",
    "#         pickle.dump(best_tuned_history.history, m_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(hist: dict):\n",
    "#     fig, ax = plt.subplots(2,1, figsize=(18, 10))\n",
    "\n",
    "#     ax[0].plot(hist['loss'], color='b', label=\"Training loss\")\n",
    "#     ax[0].plot(hist['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "#     legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "#     ax[1].plot(hist['accuracy'], color='b', label=\"Training accuracy\")\n",
    "#     ax[1].plot(hist['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "#     legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(best_tuned_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(keras_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(in_model: None, iterator: None, print_result=False):\n",
    "#     step_size = iterator.n // iterator.batch_size\n",
    "#     verb = -1\n",
    "\n",
    "#     if print_result:\n",
    "#         verb = 1\n",
    "\n",
    "#     iterator.reset()\n",
    "\n",
    "#     ls, acc = in_model.evaluate(iterator, steps=step_size, verbose=verb)\n",
    "\n",
    "#     if print_result:\n",
    "#         print(\"Loss:\\t\\t{:.6f}\\nAccuracy:\\t{:.6f}\".format(ls, acc))\n",
    "#     else:\n",
    "#         return ls, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_tuned_model, test_iterator, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(keras_model, test_iterator, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренированая модель показала худшую точность, что не радует. Но обучилась на две эпохи быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реальные цифры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_generator = ImageDataGenerator(\n",
    "#     samplewise_center=True,\n",
    "#     samplewise_std_normalization=True,\n",
    "#     rescale=1.0/255.0\n",
    "# )\n",
    "\n",
    "# #test_generator.fit(X_test)\n",
    "# true_img_iterator = true_img_generator.flow_from_directory(\n",
    "#     directory=\"./data\",\n",
    "#     target_size=(28, 28),\n",
    "#     color_mode=\"grayscale\",\n",
    "#     batch_size=1,\n",
    "#     class_mode=\"categorical\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_iterator.reset()\n",
    "\n",
    "# fig, ax = plt.subplots(5, 2, figsize=(5, 10))\n",
    "# axs = ax.flatten()\n",
    "\n",
    "# for idx in range(len(axs)):\n",
    "#     axs[idx].imshow(np.reshape(true_img_iterator[idx][0], (28, 28, 1)), cmap='gray_r')\n",
    "#     #axs[idx].imshow(true_img_iterator[idx][0])\n",
    "    \n",
    "#     img_label = np.nonzero(true_img_iterator[idx][1][0])\n",
    "    \n",
    "#     axs[idx].set_title(int(img_label[0]))\n",
    "\n",
    "#     axs[idx].xaxis.set_ticks([])\n",
    "#     axs[idx].yaxis.set_ticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут интересно, что фон не такой чистый и вобще цифры немного отличаются по масштабу и повороту. Отлично, это возможность проверить влияние аугментации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_iterator.reset()\n",
    "\n",
    "# evaluate_model(best_tuned_model, true_img_iterator, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_iterator.reset()\n",
    "\n",
    "# evaluate_model(keras_model, true_img_iterator, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss на тренированной модели меньше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_iterator.reset()\n",
    "\n",
    "# fig, ax = plt.subplots(5, 2, figsize=(5, 10))\n",
    "# axs = ax.flatten()\n",
    "\n",
    "# for idx in range(len(true_img_iterator)):\n",
    "#     best_model_predict = best_tuned_model.predict(true_img_iterator[idx][0]).argmax(-1)\n",
    "#     keras_model_predict = keras_model.predict(true_img_iterator[idx][0]).argmax(-1)\n",
    "#     ground_true = np.nonzero(true_img_iterator[idx][1])[1]\n",
    "\n",
    "#     axs[idx].imshow(np.reshape(true_img_iterator[idx][0], (28, 28, 1)), cmap='gray_r')\n",
    "    \n",
    "#     axs[idx].set_title(\"True: {}\\nBest trained: {}\\n Keras {}\".format(ground_true, best_model_predict, keras_model_predict))\n",
    "\n",
    "#     axs[idx].xaxis.set_ticks([])\n",
    "#     axs[idx].yaxis.set_ticks([])\n",
    "\n",
    "# plt.tight_layout(pad=2.0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, семерка вобще не хочет определяться. Можно бы было перетренировать модели, но я не вижу в этом смысла. Предварительно могу сказать, это связанно с тем, что в датасете почти все семерки без горизонтальной линии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем сетка проще, тем лучше. Inference быстрее, обучение быстрее. Тот случай, когда кашу маслом легко испортить. Как показал эксперимент точность может упасть вместе с производительностью, что печально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров тут тоже не панацея. Сетки нужно понимать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аугментация данных важный момент. Для картинок точно. Сетка без аугментации половину реальных цифр не узнала (этот эксперимент я не сохранил). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важность ранней остановки трудно недооценить. Это не только время, но и переобучение. Можно оставить сетку учится и не заметить, где она в оверфит ушла. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вобще callbacks это must have технология для применения в нейронках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow порадовал сохранением данных самостоятельно. Можно прервать обучение и не проводить его заново с нуля - очень удобно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большой (возможно единственный), конечно, минус нейронок это скорость. Что обучения, что inference. Но, безусловно, нелинейность заложенная изначально в саму идею творит чудеса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **P.S. Flax**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никакой моей заслуги в приведенном ниже коде нет, это совсем немного переделанный тутор <a href = https://flax.readthedocs.io/en/latest/notebooks/annotated_mnist.html>Annotated MNIST</a>.<br>\n",
    "Просто мне стало интересно сравнить производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8' # Use 8 CPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 11:18:00.026219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-04 11:18:00.026266: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-04 11:18:00.026289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-LDSDKNA): /proc/driver/nvidia/version does not exist\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "train_ds = make_dataset_from_iterator(STEP_SIZE_TRAIN, True, train_iterator)\n",
    "val_ds = make_dataset_from_iterator(STEP_SIZE_VAL, True, val_iterator)\n",
    "test_ds = make_dataset_from_iterator(STEP_SIZE_TEST, True, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DS_SIZE = len(train_ds['image'])\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x_in):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding='SAME')(x_in)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding='SAME')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=N_CLASSES)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_train_state(rng, learning_rate, momentum):\n",
    "#     \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "#     cnn = CNN()\n",
    "#     params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "#     tx = optax.sgd(learning_rate, momentum)\n",
    "#     return train_state.TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.pmap\n",
    "def get_initial_params(key):\n",
    "    init_val = jnp.ones((1, 28, 28, 1), jnp.float32)\n",
    "    initial_params = CNN().init(key, init_val)['params']\n",
    "    return initial_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(optimizer, train_ds, rng, batch_size=10):\n",
    "    #train_ds_size = TRAIN_DS_SIZE#len(train_ds['image'])\n",
    "    #steps_per_epoch = STEP_SIZE_TRAIN#train_ds_size // batch_size\n",
    "    #print(steps_per_epoch)\n",
    "\n",
    "    perms = jax.random.permutation(rng, len(train_ds['image']))\n",
    "    perms = perms[:STEP_SIZE_TRAIN * BATCH_SIZE]\n",
    "    perms = perms.reshape((STEP_SIZE_TRAIN, BATCH_SIZE))\n",
    "    batch_metrics = []\n",
    "    \n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        batch = jax_utils.replicate(batch)\n",
    "        optimizer, metrics = train_step(optimizer, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    batch_metrics_np = jax.tree_multimap(lambda *xs: np.array(xs), *batch_metrics_np)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean(batch_metrics_np[k], axis=0)\n",
    "        for k in batch_metrics_np\n",
    "    }\n",
    "\n",
    "    return optimizer, epoch_metrics_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.pmap, static_broadcasted_argnums=(1, 2))\n",
    "def create_optimizer(params, learning_rate=0.1, beta=0.9):\n",
    "  optimizer_def = optim.Adam(learning_rate=learning_rate)\n",
    "  optimizer = optimizer_def.create(params)\n",
    "  return optimizer\n",
    "\n",
    "\n",
    "@jax.pmap\n",
    "def train_step(optimizer, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = CNN().apply({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits, batch['label'])\n",
    "        return loss, logits\n",
    "        \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grad = grad_fn(optimizer.target)\n",
    "    optimizer = optimizer.apply_gradient(grad)\n",
    "    metrics = compute_metrics(logits, batch['label'])\n",
    "    return optimizer, metrics\n",
    "\n",
    "\n",
    "@jax.pmap\n",
    "def eval_step(params, batch):\n",
    "    logits = CNN().apply({'params': params}, batch['image'])\n",
    "    return compute_metrics(logits, batch['label'])\n",
    "\n",
    "\n",
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = metrics\n",
    "    return summary['loss'], summary['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, init_rng = jax.random.split(jax.random.PRNGKey(0))\n",
    "params = get_initial_params(jax.random.split(rng, jax.device_count()))\n",
    "optimizer = create_optimizer(params, 0.001, 0.9)\n",
    "\n",
    "test_ds = jax_utils.replicate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16904/2929823152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_rng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {:04d}\\nl: {}\\na: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16904/3136197105.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(params, test_ds)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16904/3136197105.py\u001b[0m in \u001b[0;36meval_step\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16904/2395970768.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/flax/linen/linear.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mdimension_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_conv_dimension_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     y = lax.conv_general_dilated(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtake\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[1;32m    188\u001b[0m            [5, 7]])\n\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'take'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    optimizer, _ = train_epoch(optimizer, train_ds, input_rng)\n",
    "\n",
    "    loss, accuracy = eval_model(optimizer.target, test_ds)\n",
    "\n",
    "    print('Epoch: {:04d}\\nl: {}\\na: {}'.format(epoch, loss, (accuracy * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
